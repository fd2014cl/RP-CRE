[training]
batch_size = 64
gradient_accumulation_steps = 4
total_round = 5
rel_per_task = 4
drop_out = 0.5
num_workers = 2
step1_epochs = 10
step2_epochs = 10
step3_epochs = 10
num_protos = 10
device = cuda
seed = 2021
max_grad_norm = 10

[Encoder]
bert_path = ./pretrained_models/bert-base-uncased
max_length = 256
vocab_size = 30522
marker_size = 4
pattern = entity_marker
encoder_output_size = 768

[memory]
key_size = 256
head_size = 768
mem_size = 768

[data]
data_file = ./data/data_with_marker_tacred.json
relation_file = ./data/id2rel_tacred.json
num_of_relation = 40
num_of_train = 420
num_of_val = 140
num_of_test = 140

